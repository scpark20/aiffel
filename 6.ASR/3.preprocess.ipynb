{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hgtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isdir, isfile, join\n",
    "\n",
    "from kspon_jamo import text_to_tokens, tokens_to_text, n_symbols, normalize_ksponspeech, SOS, EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-acting",
   "metadata": {},
   "source": [
    "### Data file 리스트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset'\n",
    "data_files = [{'wav': join(data_dir, file),\\\n",
    "               'txt': join(data_dir, file[:-3] + 'txt')} for file in listdir(data_dir) if '.wav' in file]\n",
    "print('# of data files :', len(data_files))\n",
    "data_files.sort(key=lambda x:x['txt'])\n",
    "for data_file in data_files[:10]:\n",
    "    print(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-advisory",
   "metadata": {},
   "source": [
    "### txt 파일 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = data_files[2]['txt']\n",
    "with open(file, 'r', encoding='cp949') as f:\n",
    "    l = f.read()\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-fetish",
   "metadata": {},
   "source": [
    "### 텍스트 normalization하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = normalize_ksponspeech(l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-burning",
   "metadata": {},
   "source": [
    "### token으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text_to_tokens(l)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-sheep",
   "metadata": {},
   "source": [
    "### token을 텍스트로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_recon = tokens_to_text(tokens)\n",
    "print(text_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-rwanda",
   "metadata": {},
   "source": [
    "### SOS, EOS 추가하기 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.concatenate([[SOS], tokens, [EOS]])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-guyana",
   "metadata": {},
   "source": [
    "### Pytorch Dataset Class 만들기\n",
    "dataset.py파일을 만들어 KSponSpeechDataset와 KSponSpeechDataCollate를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSponSpeechDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_files = [{'wav': join(data_dir, file),\\\n",
    "                            'txt': join(data_dir, file[:-3] + 'txt')} for file in listdir(data_dir) if '.wav' in file]\n",
    "\n",
    "    def _get_audio(self, file):\n",
    "        # (time,)\n",
    "        wav, _ = librosa.core.load(file, sr=16000, mono=True)\n",
    "        # (512, time)\n",
    "        S = librosa.feature.melspectrogram(wav, sr=16000, n_fft=1024, n_mels=80, hop_length=256, power=1.0)\n",
    "        S = (np.log10(S + 1e-5) + 5) / 5\n",
    "        # (time, 512)\n",
    "        return wav, S.T\n",
    "            \n",
    "    def _get_text(self, file):\n",
    "        with open(file, 'r', encoding='cp949') as f:\n",
    "            l = f.read()\n",
    "            l = normalize_ksponspeech(l)\n",
    "            array = text_to_tokens(l)\n",
    "        # Insert SOS and EOS\n",
    "        array = np.concatenate([[SOS], array, [EOS]])\n",
    "        return array\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        while True:\n",
    "            text = self._get_text(self.data_files[index]['txt'])\n",
    "            if len(text) > 180:\n",
    "                index = (index + 1) % self.__len__()\n",
    "                continue\n",
    "\n",
    "            wav, mel = self._get_audio(self.data_files[index]['wav'])    \n",
    "            if len(mel) > 450:\n",
    "                index = (index + 1) % self.__len__()\n",
    "                continue\n",
    "                \n",
    "            break\n",
    "        \n",
    "        return torch.FloatTensor(wav), torch.FloatTensor(mel), torch.LongTensor(text)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSponSpeechDataCollate():\n",
    "    def __call__(self, batch):\n",
    "        wav_lengths = []\n",
    "        mel_lengths = []\n",
    "        text_lengths = []\n",
    "        for wav, mel, text in batch:\n",
    "            wav_lengths.append(len(wav))\n",
    "            mel_lengths.append(len(mel))\n",
    "            text_lengths.append(len(text))\n",
    "            \n",
    "        wav_max_length = max(wav_lengths)\n",
    "        mel_max_length = max(mel_lengths)\n",
    "        text_max_length = max(text_lengths)\n",
    "        \n",
    "        wav_padded = torch.FloatTensor(len(batch), wav_max_length)\n",
    "        wav_padded.zero_()\n",
    "        mel_padded = torch.FloatTensor(len(batch), mel_max_length, 80)\n",
    "        mel_padded.fill_(-5)\n",
    "        mel_lengths = torch.from_numpy(np.array(mel_lengths)).long()\n",
    "        \n",
    "        text_padded = torch.LongTensor(len(batch), text_max_length)\n",
    "        text_padded.zero_()\n",
    "        text_lengths = torch.from_numpy(np.array(text_lengths)).long()\n",
    "        \n",
    "        for i, (wav, mel, text) in enumerate(batch):\n",
    "            wav_padded[i, :len(wav)] = wav\n",
    "            mel_padded[i, :len(mel)] = mel\n",
    "            text_padded[i, :len(text)] = text\n",
    "            \n",
    "        outputs = {'wav': wav_padded,\n",
    "                   'mel': mel_padded,\n",
    "                   'mel_lengths': mel_lengths,\n",
    "                   'text': text_padded,\n",
    "                   'text_lengths': text_lengths\n",
    "                  }\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-payday",
   "metadata": {},
   "source": [
    "### Transfer data in batch to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['mel'] = batch['mel'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-saver",
   "metadata": {},
   "source": [
    "### Dataset Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KSponSpeechDataset(data_dir='dataset')\n",
    "train_loader = DataLoader(dataset, num_workers=8, shuffle=True, batch_size=64, collate_fn=KSponSpeechDataCollate())\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-bracelet",
   "metadata": {},
   "source": [
    "### Get mel-spectrogram and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    mel = batch['mel'].data.cpu().numpy()\n",
    "    mel_lengths = batch['mel_lengths'].data.cpu().numpy()\n",
    "    text = batch['text'].data.cpu().numpy()\n",
    "    text_lengths = batch['text_lengths'].data.cpu().numpy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-prince",
   "metadata": {},
   "source": [
    "### Plot mel-spectrogram and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mel.shape)\n",
    "plt.figure(figsize=[18, 3])\n",
    "librosa.display.specshow(mel[0].T)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mel_lengths.shape)\n",
    "print(mel_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text.shape)\n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_lengths.shape)\n",
    "print(text_lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
